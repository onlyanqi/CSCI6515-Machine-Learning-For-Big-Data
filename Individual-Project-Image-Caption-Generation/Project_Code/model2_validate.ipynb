{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "from imageio import imread\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "maxlen = 20\n",
    "image_size = 224\n",
    "\n",
    "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1, 1, 3))\n",
    "\n",
    "def load_data(image_dir, annotation_path):\n",
    "    with open(annotation_path, 'r') as fr:\n",
    "        annotation = json.load(fr)\n",
    "        \n",
    "    ids = []\n",
    "    captions = []\n",
    "    image_dict = {}\n",
    "    for i in tqdm(range(len(annotation['annotations']))):\n",
    "        item = annotation['annotations'][i]\n",
    "        caption = item['caption'].strip().lower()\n",
    "        caption = caption.replace('.', '').replace(',', '').replace(\"'\", '').replace('\"', '')\n",
    "        caption = caption.replace('&', 'and').replace('(', '').replace(')', '').replace('-', ' ').split()\n",
    "        caption = [w for w in caption if len(w) > 0]\n",
    "        \n",
    "        if len(caption) <= maxlen:\n",
    "            if not item['image_id'] in image_dict:\n",
    "                img = imread(image_dir + '%012d.jpg' % item['image_id'])\n",
    "                h = img.shape[0]\n",
    "                w = img.shape[1]\n",
    "                if h > w:\n",
    "                    img = img[h // 2 - w // 2: h // 2 + w // 2, :]\n",
    "                else:\n",
    "                    img = img[:, w // 2 - h // 2: w // 2 + h // 2]   \n",
    "                img = cv2.resize(img, (image_size, image_size))\n",
    "                \n",
    "                if len(img.shape) < 3:\n",
    "                    img = np.expand_dims(img, -1)\n",
    "                    img = np.concatenate([img, img, img], axis=-1)\n",
    "                \n",
    "                image_dict[item['image_id']] = img\n",
    "            \n",
    "            ids.append(item['image_id'])\n",
    "            captions.append(caption)\n",
    "    \n",
    "    return ids, captions, image_dict\n",
    "\n",
    "val_json = 'data/val/captions_val2014.json'\n",
    "val_ids, val_captions, val_dict = load_data('data/val/images/COCO_val2014_', val_json)\n",
    "print(len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {}\n",
    "for i in tqdm(range(len(val_ids))):\n",
    "    val_id = val_ids[i]\n",
    "    if not val_id in gt:\n",
    "        gt[val_id] = []\n",
    "    gt[val_id].append(' '.join(val_captions[i]) + ' .')\n",
    "print(len(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary.pkl', 'rb') as fr:\n",
    "    [vocabulary, word2id, id2word] = pickle.load(fr)\n",
    "\n",
    "def translate(ids):\n",
    "    words = [id2word[i] for i in ids if i >= 3]\n",
    "    return ' '.join(words) + ' .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = scipy.io.loadmat('imagenet-vgg-verydeep-19.mat')\n",
    "vgg_layers = vgg['layers']\n",
    "\n",
    "def vgg_endpoints(inputs, reuse=None):\n",
    "    with tf.variable_scope('endpoints', reuse=reuse):\n",
    "        def _weights(layer, expected_layer_name):\n",
    "            W = vgg_layers[0][layer][0][0][2][0][0]\n",
    "            b = vgg_layers[0][layer][0][0][2][0][1]\n",
    "            layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "            assert layer_name == expected_layer_name\n",
    "            return W, b\n",
    "\n",
    "        def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "            W, b = _weights(layer, layer_name)\n",
    "            W = tf.constant(W)\n",
    "            b = tf.constant(np.reshape(b, (b.size)))\n",
    "            return tf.nn.relu(tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b)\n",
    "\n",
    "        def _avgpool(prev_layer):\n",
    "            return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        graph = {}\n",
    "        graph['conv1_1']  = _conv2d_relu(inputs, 0, 'conv1_1')\n",
    "        graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "        graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "        graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "        graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "        graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "        graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "        graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "        graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "        graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "        graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "        graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "        graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "        graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "        graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "        graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "        graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "        graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "        graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "        graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "        graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "\n",
    "        return graph\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, image_size, image_size, 3])\n",
    "encoded = vgg_endpoints(X - MEAN_VALUES)['conv5_3']\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_initializer = tf.contrib.layers.xavier_initializer()\n",
    "b_initializer = tf.constant_initializer(0.0)\n",
    "e_initializer = tf.random_uniform_initializer(-1.0, 1.0)\n",
    "\n",
    "def dense(inputs, units, activation=tf.nn.tanh, use_bias=True, name=None):\n",
    "    return tf.layers.dense(inputs, units, activation, use_bias,\n",
    "                           kernel_initializer=k_initializer, bias_initializer=b_initializer, name=name)\n",
    "\n",
    "def batch_norm(inputs, name):\n",
    "    return tf.contrib.layers.batch_norm(inputs, decay=0.95, center=True, scale=True, is_training=False, \n",
    "                                        updates_collections=None, scope=name)\n",
    "\n",
    "def dropout(inputs):\n",
    "    return tf.layers.dropout(inputs, rate=0.5, training=False)\n",
    "\n",
    "num_block = 14 * 14\n",
    "num_filter = 512\n",
    "hidden_size = 1024\n",
    "embedding_size = 512\n",
    "\n",
    "encoded = tf.reshape(encoded, [-1, num_block, num_filter]) # batch_size, num_block, num_filter\n",
    "contexts = batch_norm(encoded, 'contexts')\n",
    "\n",
    "with tf.variable_scope('initialize'):\n",
    "    context_mean = tf.reduce_mean(contexts, 1)\n",
    "    initial_state = dense(context_mean, hidden_size, name='initial_state')\n",
    "    initial_memory = dense(context_mean, hidden_size, name='initial_memory')\n",
    "    \n",
    "contexts_phr = tf.placeholder(tf.float32, [None, num_block, num_filter])\n",
    "last_memory = tf.placeholder(tf.float32, [None, hidden_size])\n",
    "last_state = tf.placeholder(tf.float32, [None, hidden_size])\n",
    "last_word = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "with tf.variable_scope('embedding'):\n",
    "    embeddings = tf.get_variable('weights', [len(word2id), embedding_size], initializer=e_initializer)\n",
    "    embedded = tf.nn.embedding_lookup(embeddings, last_word)\n",
    "    \n",
    "with tf.variable_scope('projected'):\n",
    "    projected_contexts = tf.reshape(contexts_phr, [-1, num_filter]) # batch_size * num_block, num_filter\n",
    "    projected_contexts = dense(projected_contexts, num_filter, activation=None, use_bias=False, name='projected_contexts')\n",
    "    projected_contexts = tf.reshape(projected_contexts, [-1, num_block, num_filter]) # batch_size, num_block, num_filter\n",
    "\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('attend'):\n",
    "    h0 = dense(last_state, num_filter, activation=None, name='fc_state') # batch_size, num_filter\n",
    "    h0 = tf.nn.relu(projected_contexts + tf.expand_dims(h0, 1)) # batch_size, num_block, num_filter\n",
    "    h0 = tf.reshape(h0, [-1, num_filter]) # batch_size * num_block, num_filter\n",
    "    h0 = dense(h0, 1, activation=None, use_bias=False, name='fc_attention') # batch_size * num_block, 1\n",
    "    h0 = tf.reshape(h0, [-1, num_block]) # batch_size, num_block\n",
    "\n",
    "    alpha = tf.nn.softmax(h0) # batch_size, num_block\n",
    "    # contexts:                 batch_size, num_block, num_filter\n",
    "    # tf.expand_dims(alpha, 2): batch_size, num_block, 1\n",
    "    context = tf.reduce_sum(contexts_phr * tf.expand_dims(alpha, 2), 1, name='context') # batch_size, num_filter\n",
    "\n",
    "with tf.variable_scope('selector'):\n",
    "    beta = dense(last_state, 1, activation=tf.nn.sigmoid, name='fc_beta') # batch_size, 1\n",
    "    context = tf.multiply(beta, context, name='selected_context')  # batch_size, num_filter\n",
    "\n",
    "with tf.variable_scope('lstm'):\n",
    "    h0 = tf.concat([embedded, context], 1) # batch_size, embedding_size + num_filter\n",
    "    _, (current_memory, current_state) = lstm(inputs=h0, state=[last_memory, last_state])\n",
    "\n",
    "with tf.variable_scope('decode'):\n",
    "    h0 = dropout(current_state)\n",
    "    h0 = dense(h0, embedding_size, activation=None, name='fc_logits_state')\n",
    "    h0 += dense(context, embedding_size, activation=None, use_bias=False, name='fc_logits_context')\n",
    "    h0 += embedded\n",
    "    h0 = tf.nn.tanh(h0)\n",
    "\n",
    "    h0 = dropout(h0)\n",
    "    logits = dense(h0, len(word2id), activation=None, name='fc_logits')\n",
    "    probs = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = 'model'\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint(MODEL_DIR))\n",
    "\n",
    "beam_size = 1\n",
    "id2sentence = {}\n",
    "\n",
    "val_ids = list(set(val_ids))\n",
    "if len(val_ids) % batch_size != 0:\n",
    "    for i in range(batch_size - len(val_ids) % batch_size):\n",
    "        val_ids.append(val_ids[0])\n",
    "print(len(val_ids))\n",
    "\n",
    "for i in tqdm(range(len(val_ids) // batch_size)):\n",
    "    X_batch = np.array([val_dict[x] for x in val_ids[i * batch_size: i * batch_size + batch_size]])\n",
    "    contexts_, initial_memory_, initial_state_ = sess.run([contexts, initial_memory, initial_state], feed_dict={X: X_batch})\n",
    "\n",
    "    result = []\n",
    "    complete = []\n",
    "    for b in range(batch_size):\n",
    "        result.append([{\n",
    "            'sentence': [], \n",
    "            'memory': initial_memory_[b], \n",
    "            'state': initial_state_[b],\n",
    "            'score': 1.0,\n",
    "            'alphas': []\n",
    "        }])\n",
    "        complete.append([])\n",
    "\n",
    "    for t in range(maxlen + 1):\n",
    "        cache = [[] for b in range(batch_size)]\n",
    "        step = 1 if t == 0 else beam_size\n",
    "        for s in range(step):\n",
    "            if t == 0:\n",
    "                last_word_ = np.ones([batch_size], np.int32) * word2id['<start>']\n",
    "            else:\n",
    "                last_word_ = np.array([result[b][s]['sentence'][-1] for b in range(batch_size)], np.int32)\n",
    "\n",
    "            last_memory_ = np.array([result[b][s]['memory'] for b in range(batch_size)], np.float32)\n",
    "            last_state_ = np.array([result[b][s]['state'] for b in range(batch_size)], np.float32)\n",
    "\n",
    "            current_memory_, current_state_, probs_, alpha_ = sess.run(\n",
    "                [current_memory, current_state, probs, alpha], feed_dict={\n",
    "                    contexts_phr: contexts_, \n",
    "                    last_memory: last_memory_,\n",
    "                    last_state: last_state_,\n",
    "                    last_word: last_word_\n",
    "                    })\n",
    "            \n",
    "            for b in range(batch_size):\n",
    "                word_and_probs = [[w, p] for w, p in enumerate(probs_[b])]\n",
    "                word_and_probs.sort(key=lambda x:-x[1])\n",
    "                word_and_probs = word_and_probs[:beam_size + 1]\n",
    "\n",
    "                for w, p in word_and_probs:\n",
    "                    item = {\n",
    "                        'sentence': result[b][s]['sentence'] + [w], \n",
    "                        'memory': current_memory_[b], \n",
    "                        'state': current_state_[b],\n",
    "                        'score': result[b][s]['score'] * p,\n",
    "                        'alphas': result[b][s]['alphas'] + [alpha_[b]]\n",
    "                    }\n",
    "\n",
    "                    if id2word[w] == '<end>':\n",
    "                        complete[b].append(item)\n",
    "                    else:\n",
    "                        cache[b].append(item)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            cache[b].sort(key=lambda x:-x['score'])\n",
    "            cache[b] = cache[b][:beam_size]\n",
    "        result = cache.copy()\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        if len(complete[b]) == 0:\n",
    "            final_sentence = result[b][0]['sentence']\n",
    "        else:\n",
    "            final_sentence = complete[b][0]['sentence']\n",
    "        \n",
    "        val_id = val_ids[i * batch_size + b] \n",
    "        if not val_id in id2sentence:\n",
    "            id2sentence[val_id] = [translate(final_sentence)]\n",
    "\n",
    "print(len(id2sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated.txt', 'w') as fw:\n",
    "    for i in id2sentence.keys():\n",
    "        fw.write(str(i) + '^' + id2sentence[i][0] + '^' + '_'.join(gt[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 435873, 'reflen': 431236, 'guess': [435873, 395369, 354865, 314361], 'correct': [299794, 132419, 57743, 25805]}\n",
      "ratio: 1.0107528128449363\n",
      "Bleu_1 0.6878012632119891\n",
      "Bleu_2 0.4799603146327394\n",
      "Bleu_3 0.33466909679908385\n",
      "Bleu_4 0.2355214731874305\n",
      "ROUGE_L 0.5304592073317095\n",
      "CIDEr 0.7292663614238141\n"
     ]
    }
   ],
   "source": [
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "id2sentence = {}\n",
    "gt = {}\n",
    "with open('generated.txt', 'r') as fr:\n",
    "    lines = fr.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('^')\n",
    "        i = line[0]\n",
    "        id2sentence[i] = [line[1]]\n",
    "        gt[i] = line[2].split('_')\n",
    "\n",
    "scorers = [\n",
    "    (Bleu(4), ['Bleu_1', 'Bleu_2', 'Bleu_3', 'Bleu_4']),\n",
    "    (Rouge(), 'ROUGE_L'),\n",
    "    (Cider(), 'CIDEr')\n",
    "]\n",
    "\n",
    "for scorer, name in scorers:\n",
    "    score, _ = scorer.compute_score(gt, id2sentence)\n",
    "    if type(score) == list:\n",
    "        for n, s in zip(name, score):\n",
    "            print(n, s)\n",
    "    else:\n",
    "        print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
